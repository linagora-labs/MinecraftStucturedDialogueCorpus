{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505b0e3f-f343-4d80-b629-37db793eb876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e6c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f46b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c899cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for GPU\n",
    "torch.cuda.is_available()\n",
    "# device = torch.device('cuda')\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea08a4-3441-4461-a77c-326dee410805",
   "metadata": {},
   "outputs": [],
   "source": [
    "+\n",
    "import random\n",
    "import time\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153bb336",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_relations = {'Comment':0, 'Contrast':1, 'Correction':2, 'Question-answer_pair':3, 'Acknowledgement':4,'Elaboration':5,\n",
    "                 'Clarification_question':6, 'Conditional':7, 'Continuation':8, 'Result':9, 'Explanation':10, 'Q-Elab':11,\n",
    "                 'Alternation':12, 'Narration':13, 'Confirmation_question':14, 'Sequence':15, 'Break':16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd422b6-eae8-4d65-87fe-12fcde1d5b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "home=%pwd\n",
    "filename = home + '/data/TRAIN+VAL_407_bert.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71de8c0",
   "metadata": {},
   "source": [
    "load and preprocess the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3ccf1f-b088-429b-945b-80c36c24de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data, input_format, position_ids_compute, tokenize\n",
    "from bert_format import undersample, format_time, flat_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ca18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(filename, map_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split out a certain portion of validation data (a function of length?)\n",
    "train_data = data[40:]\n",
    "valid_data = data[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d527f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text_train, labels_complete_train, raw_train = input_format(data, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd9191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text_val, labels_complete_val, raw_val = input_format(valid_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132dab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tokenizer and token ids\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6abcec",
   "metadata": {},
   "source": [
    "Add special tokens for moves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30dc5a1-da79-4213-98dd-7c188a981f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "put = ['1','0']\n",
    "colors = ['r', 'b', 'g', 'o', 'y', 'p']\n",
    "listx = ['b', 'c', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n']\n",
    "listy = ['0', '1', '2', '3', '4', '5', '6', '7', '8']\n",
    "listz = ['a', 'e', 'i', 'o', 'u', 'p', 'q', 'r', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd8d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_tokens = [''.join([s, t, i, j, k]) for s in put\n",
    "                for t in colors\n",
    "                for i in listx\n",
    "                for j in listy\n",
    "                for k in listz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d69a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_tokens(coord_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50509876",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2482706",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481e394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train, attention_masks_train, token_type_ids_train = tokenize(input_text_train, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c255d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_val, attention_masks_val, token_type_ids_val = tokenize(input_text_val, tokenizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaaa118",
   "metadata": {},
   "source": [
    "Compute position ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc31244-405f-4a50-aee8-bda30f991cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_train = position_ids_compute(tokenizer, input_ids_train, raw_train, labels_complete_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f8b622-400d-4a7e-b209-15b2cec47bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_val = position_ids_compute(tokenizer, input_ids_val, raw_val, labels_complete_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894e22a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_train = torch.tensor(position_ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b929b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_val = torch.tensor(position_ids_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb9c4df",
   "metadata": {},
   "source": [
    "Undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d049058",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = [l[3] for l in labels_complete_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f0b9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val = [l[3] for l in labels_complete_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743e18e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = torch.tensor(labels_train)\n",
    "labels_val = torch.tensor(labels_val)\n",
    "labels_complete_train = torch.tensor(labels_complete_train)\n",
    "labels_complete_val = torch.tensor(labels_complete_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565fcb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB need to choose a number to keep\n",
    "#usually about 60% of total candidates\n",
    "labels_complete_train, labels_train, input_ids_train, attention_masks_train, token_type_ids_train, position_ids_train = undersample(103400, labels_complete_train, labels_train, input_ids_train, attention_masks_train, token_type_ids_train, position_ids_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f059a9b",
   "metadata": {},
   "source": [
    "Load data loader and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a12e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defcf37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(input_ids_train, attention_masks_train, token_type_ids_train, position_ids_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5500be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TensorDataset(input_ids_val, attention_masks_val, token_type_ids_val, position_ids_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0436fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset),\n",
    "            batch_size = 32\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebf096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            sampler = SequentialSampler(val_dataset),\n",
    "            batch_size = 32\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e97831",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-cased',\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = True, attention_probs_dropout_prob=0, hidden_dropout_prob=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c1391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!important -- must add new token embeddings to BERT\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b960960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98e5328",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 1.5e-5,\n",
    "                  eps = 1e-8\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ccb45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = len(train_dataloader) * 2\n",
    "seed_val = 18\n",
    "total_t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4df5625",
   "metadata": {},
   "source": [
    "Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3718ac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = home + '<name of your model folder>'\n",
    "bert_name = '<name of your .pth file output>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cb4033",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_i in range(2):\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, 2))\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        result = model(batch[0].to(device),\n",
    "                       token_type_ids=batch[2].to(device),\n",
    "                       attention_mask=batch[1].to(device),\n",
    "                       position_ids = batch[3].to(device),\n",
    "                       labels=batch[4].to(device),\n",
    "                       return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"  Training Loss: \",avg_train_loss)\n",
    "    print(\"  Training took: \", training_time)\n",
    "    print(\"Running Validation\")\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Evaluation step\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            result = model(batch[0].to(device),\n",
    "                           token_type_ids=batch[2].to(device),\n",
    "                           attention_mask=batch[1].to(device),\n",
    "                           position_ids = batch[3].to(device),\n",
    "                           labels=batch[4].to(device),\n",
    "                           return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = batch[4].to(device).cpu().numpy()\n",
    "\n",
    "        # Compute the accuracy\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: \", avg_val_accuracy)\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"  Validation Loss: \", avg_val_loss)\n",
    "    print(\"  Validation took: \",validation_time)\n",
    "print(\"Training complete!\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "}, model_path + bert_name + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078e0949",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db17e40",
   "metadata": {},
   "source": [
    "Get scores on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd1b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test data\n",
    "filename = home + '/data/TEST_101_bert.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e4372",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_data(filename, map_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ffd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text_test, labels_complete_test, raw_test = input_format(test_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec31cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_test, attention_masks_test, token_type_ids_test = tokenize(input_text_test, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088da1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_test = position_ids_compute(tokenizer, input_ids_test, raw_test, labels_complete_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dfe326",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_test = torch.tensor(position_ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29349aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = [l[3] for l in labels_complete_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e725685",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = torch.tensor(labels_test)\n",
    "labels_complete_test = torch.tensor(labels_complete_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f45bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(input_ids_test, attention_masks_test, token_type_ids_test, position_ids_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5344268",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            sampler = SequentialSampler(test_dataset),\n",
    "            batch_size = 32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72d82a3",
   "metadata": {},
   "source": [
    "start :: if need to reload the model to run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ecfd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = home + '<name of your model folder>/<name of your .pth file output>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48042df",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-cased',\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = True, attention_probs_dropout_prob=0, hidden_dropout_prob=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240aeb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fe859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "embedder.load_state_dict(checkpoint['model_state_dict'])\n",
    "embedder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae7653d",
   "metadata": {},
   "source": [
    "End :: if you needed to reload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5bf6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test cands...'.format(len(input_ids_test)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables\n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict\n",
    "for batch in test_dataloader:\n",
    "  # # Add batch to GPU\n",
    "  # batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "  # # Unpack the inputs from our dataloader\n",
    "  # b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "  # # Telling the model not to compute or store gradients, saving memory and\n",
    "  # # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions.\n",
    "      result = model(batch[0].to(device),\n",
    "                      token_type_ids=batch[2].to(device),\n",
    "                      attention_mask=batch[1].to(device),\n",
    "                      position_ids = batch[3].to(device),\n",
    "                      labels=batch[4].to(device),\n",
    "                      return_dict=True)\n",
    "\n",
    "  logits = result.logits\n",
    "\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = batch[4].to(device).cpu().numpy()\n",
    "\n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d481e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63679f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c364bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the results across all batches.\n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af45736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d7c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(flat_true_labels, flat_predictions, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf4dde8",
   "metadata": {},
   "source": [
    "save output <br>\n",
    "list of lists with [dialogue index, x index, y index, true attach, true label, predicted attach]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
